# Automated Voice AI Testing Framework

**Enterprise-grade testing platform for voice AI systems with proven 99.7% validation accuracy**

A comprehensive, production-ready testing framework specifically designed for automated validation of voice AI systems in automotive and enterprise environments. Built with a human-in-the-loop approach to combine automation speed with human quality assurance.

---

## ðŸŽ¯ Overview

The Automated Voice AI Testing Framework is a complete solution for testing voice-enabled applications, with primary focus on SoundHound Voice AI integration. It delivers automotive-grade reliability through a unique combination of automated testing at scale and expert human validation.

### Key Metrics

* **99.7% Validation Accuracy** - Proven track record with major automotive OEMs
* **1000+ Tests/Day** - High-volume execution capability (scalable to 10,000+)
* **<4 Hour Feedback Cycles** - Rapid iteration from test to results
* **8+ Languages Supported** - Multi-language validation capability
* **Real-time Monitoring** - Live dashboards and CI/CD integration

---

## Key Features

### Automated Testing at Scale
* **High-volume execution**: Run 1000+ voice interaction tests daily
* **Parallel execution engines**: Voice simulation, device control, response validation
* **Multi-language support**: Validate across 8+ major language families
* **Continuous regression testing**: Automated detection of quality degradation
* **End-to-end system integration**: Full workflow testing from voice input to system response

### Human-in-the-Loop Validation
* **Expert quality assurance**: Native speaker validation for edge cases
* **Context-aware evaluation**: Semantic accuracy verification beyond simple matching
* **Continuous standard refinement**: Validation rules improve with human feedback
* **99.7% accuracy achievement**: Proven results through ML + human validation

### Production-Ready Infrastructure
* **Real-time dashboards**: Executive summaries, defect tracking, trend analysis
* **CI/CD integration**: Webhooks for GitHub, GitLab, Jenkins
* **Automotive-grade standards**: ISO 26262 compliance considerations
* **Flexible deployment**: On-premise, cloud, or hybrid configurations
* **Enterprise features**: Multi-tenancy, RBAC, SSO, audit logging

### Advanced Capabilities
* **ML-powered validation**: Semantic similarity matching using transformer models
* **Edge case library**: 300+ documented edge cases and handling strategies
* **Defect detection**: Automatic pattern recognition and categorization
* **Performance monitoring**: Response time analysis, throughput tracking
* **Test case versioning**: Complete history and rollback capability

---

## System Architecture

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Web Dashboard (React)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Gateway (FastAPI)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestrationâ”‚      â”‚  Execution   â”‚      â”‚  Validation  â”‚
â”‚   Service    â”‚      â”‚   Engines    â”‚      â”‚   Service    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                     â”‚                     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Message Queue (RabbitMQ/Celery)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚      â”‚   MongoDB    â”‚      â”‚    Redis     â”‚
â”‚  (Metadata)  â”‚      â”‚  (Results)   â”‚      â”‚   (Cache)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 External Integrations                        â”‚
â”‚     SoundHound API â”‚ GitHub â”‚ Jira â”‚ Slack â”‚ AWS S3        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Core Components

1. **Test Orchestration Layer**: Manages test execution, scheduling, and coordination
2. **Execution Engines**: Three parallel engines for voice, device, and validation
3. **Human Validation Layer**: Quality assurance for edge cases and low-confidence results
4. **Reporting & Analytics**: Real-time dashboards, defect tracking, trend analysis
5. **Integration Layer**: CI/CD pipelines, external tools, notification systems

---

## ðŸ—‚ï¸ Project Structure

```
automated-testing/
â”œâ”€â”€ backend/                 # Python/FastAPI backend
â”‚   â”œâ”€â”€ api/                # API endpoints and routes
â”‚   â”œâ”€â”€ services/           # Business logic layer
â”‚   â”œâ”€â”€ models/             # SQLAlchemy database models
â”‚   â”œâ”€â”€ tests/              # Backend test suites
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ frontend/               # React/TypeScript frontend
â”‚   â”œâ”€â”€ src/               # Source code
â”‚   â”œâ”€â”€ public/            # Static assets
â”‚   â””â”€â”€ package.json       # Node.js dependencies
â”œâ”€â”€ infrastructure/         # Infrastructure as Code
â”‚   â”œâ”€â”€ terraform/         # AWS/Cloud infrastructure
â”‚   â””â”€â”€ docker/            # Docker configurations
â”œâ”€â”€ docs/                  # Documentation
â”œâ”€â”€ scripts/               # Automation scripts
â””â”€â”€ tests/                 # Integration & E2E tests
```

---

## Prerequisites

Before setting up the project, ensure you have the following installed:

### Required Software

* **Python 3.11+** - Backend application runtime
* **Node.js 20+** - Frontend development and build tools
* **PostgreSQL 15+** - Primary database for transactional data
* **Redis 7+** - Cache and message queue backend
* **Docker & Docker Compose** - Containerized development environment

### Optional (for production)

* **RabbitMQ 3.12+** - Alternative message queue (production recommended)
* **MongoDB 7+** - Document store for test results (optional)
* **Git** - Version control

### Development Tools (Recommended)

* **VS Code** or **PyCharm** - IDE
* **Postman** or **Insomnia** - API testing
* **pgAdmin** or **DBeaver** - Database management

---

## Installation

### Option 1: Docker Setup (Recommended)

The fastest way to get started is using Docker:

```bash
# Clone the repository
git clone https://github.com/your-org/automated-testing.git
cd automated-testing

# Start all services with Docker Compose
docker-compose up -d

# Run database migrations
docker-compose exec backend alembic upgrade head

# Access the application
# Backend API: http://localhost:8000
# Frontend: http://localhost:3000
# API Docs: http://localhost:8000/api/docs
```

### Option 2: Local Development Setup

For local development without Docker:

#### Backend Setup

```bash
# Navigate to backend directory
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your configuration

# Run database migrations
alembic upgrade head

# Start the backend server
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

#### Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Set up environment variables
cp .env.example .env
# Edit .env with your configuration

# Start development server
npm run dev

# Access at http://localhost:3000
```

#### Database Setup

```bash
# Start PostgreSQL (macOS with Homebrew)
brew services start postgresql

# Create database
createdb voice_ai_testing

# Start Redis
brew services start redis

# Or using Docker for databases only
docker-compose up -d postgres redis
```

---

## ðŸƒ Running Locally

### Start All Services

```bash
# Using Docker Compose (all services)
docker-compose up

# Or start individually
docker-compose up backend
docker-compose up frontend
docker-compose up postgres
docker-compose up redis
```

### Run Development Servers

```bash
# Terminal 1: Backend
cd backend
source venv/bin/activate
uvicorn api.main:app --reload

# Terminal 2: Frontend
cd frontend
npm run dev

# Terminal 3: Celery Worker (for background tasks)
cd backend
celery -A celery_app worker --loglevel=info

# Terminal 4: Celery Beat (for scheduled tasks)
cd backend
celery -A celery_app beat --loglevel=info
```

### Access Points

* **Frontend Application**: http://localhost:3000
* **Backend API**: http://localhost:8000
* **API Documentation (Swagger)**: http://localhost:8000/api/docs
* **Alternative API Docs (ReDoc)**: http://localhost:8000/api/redoc
* **Prometheus Metrics**: http://localhost:9090
* **Grafana Dashboards**: http://localhost:3000 (admin/changeme_grafana)
* **PostgreSQL**: localhost:5432 (default credentials in docker-compose.yml)
* **Redis**: localhost:6379
* **RabbitMQ Management**: http://localhost:15672 (rabbitmq/rabbitmq)
* **MinIO Console**: http://localhost:9001 (minio_user/changeme_minio_s3)

---

## Testing

### Run All Tests

```bash
# Backend tests with pytest
cd backend
pytest

# With coverage report
pytest --cov=. --cov-report=html

# Frontend tests with Vitest
cd frontend
npm test

# Run specific test file
npm test src/components/TestCase.test.tsx
```

### Test Categories

```bash
# Unit tests only
pytest tests/unit/

# Integration tests
pytest tests/integration/

# End-to-end tests
pytest tests/e2e/

# Run with markers
pytest -m "not slow"
pytest -m integration
```

### Linting and Code Quality

```bash
# Backend linting
cd backend
ruff check .
black --check .

# Frontend linting
cd frontend
npm run lint
npm run format:check

# Fix issues automatically
npm run lint:fix
npm run format
```

---

## ðŸ“Š Usage Examples

### Running a Test Suite

```python
# Using Python API client
from api.client import TestClient

client = TestClient(api_key="your-api-key")

# Create a test run
test_run = client.create_test_run(
    suite_id="suite-123",
    languages=["en-US", "es-ES"],
    trigger_type="manual"
)

# Monitor progress
while test_run.status != "completed":
    test_run = client.get_test_run(test_run.id)
    print(f"Progress: {test_run.progress}%")
    time.sleep(5)

# Get results
results = client.get_test_results(test_run.id)
print(f"Passed: {results.passed}, Failed: {results.failed}")
```

### Using the CLI

```bash
# Run a test suite
./scripts/run-tests.sh --suite navigation --languages en-US,es-ES

# Run specific test cases
./scripts/run-tests.sh --test-ids TC-001,TC-002,TC-003

# Schedule regression suite
./scripts/schedule-regression.sh --cron "0 2 * * *"
```

---

## ðŸ”§ Configuration

### Environment Variables

Key environment variables (see `.env.example` for complete list):

```bash
# Database
DATABASE_URL=postgresql://user:password@localhost:5432/voice_ai_testing
REDIS_URL=redis://localhost:6379/0

# SoundHound API
SOUNDHOUND_API_KEY=your-api-key
SOUNDHOUND_CLIENT_ID=your-client-id
SOUNDHOUND_ENDPOINT=https://api.soundhound.com/v2

# JWT Authentication
JWT_SECRET_KEY=your-secret-key
JWT_ALGORITHM=HS256
JWT_EXPIRATION_MINUTES=60

### Refresh token rotation

- Every successful call to `/api/v1/auth/login` or `/api/v1/auth/refresh` issues a brand-new refresh token.
- The backend (via `RefreshTokenStore`) immediately revokes all previously issued refresh tokens for that user, ensuring only the latest token remains valid.
- `/api/v1/auth/logout` explicitly revokes the submitted refresh token.
- Clients must persist the newest refresh token and discard older copies; attempting to reuse any stale token will return `401`.

### RBAC roles

- `admin`: full control, including configuration changes, user provisioning, and destructive actions.
- `qa_lead`: manage test content and configurations but not platform-level settings.
- `validator`: limited to validation workflows (claiming/completing human validation tasks).
- `viewer`: read-only dashboards and reports.

Critical endpoints such as configuration mutations, user management, and deletion of test cases enforce these roles.

# AWS (for S3 storage)
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION=us-east-1
AWS_S3_BUCKET=voice-ai-testing

# Application
ENVIRONMENT=development  # development, staging, production
LOG_LEVEL=INFO
ENABLE_DEBUG=true

### Secret Management

- **Kubernetes/Secrets Manager**: In staging and production, copy the values shown in `.env.example` into your Kubernetes `Secret` manifests (or your cloud secrets manager) rather than storing real credentials in source control. The deployment manifests should mount those secrets as environment variables (e.g., `JWT_SECRET_KEY`, `SOUNDHOUND_API_KEY`, `AWS_*`).
- **Local development**: `.env.example` contains placeholders only; run `cp .env.example .env` and populate with developer-only credentials. Never reuse local secrets in shared environments.
- **Rotation**: Adopt a quarterly rotation for SoundHound and AWS credentials. When rotating, update the secret in your secrets manager first, trigger a rolling restart of backend pods, and finally revoke the previous credentials. Document each rotation in your runbook so auditors can trace when tokens changed.
- **Access controls**: Limit read/write access to the secret store to the platform team. CI pipelines should consume secrets through managed runners rather than plaintext files checked into git.
```

---

## ðŸ“š Documentation

Comprehensive documentation is available in the `/docs` directory:

* **[API Reference](docs/api-reference.md)** - Complete API documentation
* **[Architecture Guide](docs/architecture.md)** - System architecture details
* **[Setup Guide](docs/setup-guide.md)** - Detailed installation instructions
* **[Development Guide](docs/development.md)** - Contributing guidelines
* **[Deployment Guide](docs/deployment.md)** - Production deployment
* **[User Manual](docs/user-manual.md)** - End-user documentation
* **[Troubleshooting](docs/troubleshooting.md)** - Common issues and solutions

Also see:
* **[MVP Specification](MVP.md)** - Complete MVP requirements
* **[Task List](TODOS.md)** - Development task breakdown

---

## ðŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/your-feature-name`
3. **Make your changes** with tests
4. **Run the test suite**: `pytest` and `npm test`
5. **Commit your changes**: `git commit -m "Add your feature"`
6. **Push to your fork**: `git push origin feature/your-feature-name`
7. **Create a Pull Request**

### Development Guidelines

* Follow TDD (Test-Driven Development) approach
* Maintain test coverage above 80%
* Use conventional commit messages
* Update documentation for new features
* Run linters before committing

See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for detailed guidelines.

---

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ðŸ’¬ Support & Contact

### Getting Help

* **Issues & Bugs**: [GitHub Issues](https://github.com/your-org/automated-testing/issues)
* **Questions**: [GitHub Discussions](https://github.com/your-org/automated-testing/discussions)
* **Email**: support@productiveplayhouse.com

### Commercial Support

For enterprise support, custom development, or consulting:

* **Email**: sales@productiveplayhouse.com
* **Website**: https://productiveplayhouse.com

---

## ðŸ™ Acknowledgments

* **SoundHound Inc.** - Voice AI technology partner
* **Major Automotive OEM** - Pilot program collaboration
* All contributors and testers who helped achieve 99.7% validation accuracy

---

## ðŸ“ˆ Roadmap

### Current Version: 0.1.0 (MVP)

* âœ… Core testing framework
* âœ… SoundHound integration
* âœ… Human validation system
* âœ… Real-time dashboards
* âœ… Multi-language support (8 languages)

### Planned Features

* **Q2 2025**: Mobile app for validators
* **Q3 2025**: AI-powered test case generation
* **Q4 2025**: Visual regression testing
* **2026**: Performance testing module, Accessibility testing

See [ROADMAP.md](docs/ROADMAP.md) for detailed planning.

---

**Built with â¤ï¸ by Nathaniel Adika**

*Delivering automotive-grade voice AI testing with proven 99.7% accuracy*
